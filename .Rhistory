allTables[1:5]
dbListFields(hg19,"affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
# Select a specific subset
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis <- fetch(query); quantile(affyMis$misMatches)
affyMisSmall <- fetch(query, n=10); dbClearResult(query);
dim(affyMisSmall)
dbDisconnect(hg19)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created = h5createFile("example.h5"
created
created = h5createFile("example.h5")
created
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
close(con)
htmlCode
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = T)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
install.packages("httr")
library(httr); html2 = GET(url)
content2 = content(html2, as="text")
parsedHtml = htmlParse(content2, astext=TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
library(XML)
library(httr); html2 = GET(url)
content2 = content(html2, as="text")
parsedHtml = htmlParse(content2, astext=TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
?parsedHtml
??parsedHtml
?htmlParse
parsedHtml = htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
pg1 = GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg2 = GET("http://httpbin.org/basic-auth/user/passwd", authenticate("user", "passwd"))
pg2
names(pg2)
?handle
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
library(httr); html2 = GET(url)
content2 = content(html2, as="text")
?htmlParse
parsedHtml = htmlParse(content2, asText=TRUE)
library(XML)
?htmlParse
parsedHtml = htmlParse(content2, asText=TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
parsedHtml[1:5]
parsedHtml
class(parsedHtml)
parsedHtml.HTMLInternalDocument
print(parsedHtml)
con = url(url)
htmlCode = readLines(con)
close(con)
htmlCode
htmlCode[1]
nchar(htmlCode[1])
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
the_file = "/Users/JerryTsai/userjst/individ/knowledg/cur/jhu.sph/ds03_getdata/quizzes/quiz02/getdata-wksst8110.for"
qqq <- read.fwf(the_file, c(10,3,2), header = FALSE, sep = "\t",
skip = 4)
qqq[1]
qqq <- read.fwf(the_file, c(10,3,2), header = FALSE, sep = " ",
skip = 4)
qqq[1]
qqq <- read.fwf(the_file, widths=c(10,8), header = FALSE, sep = " ", skip = 4)
qqq[1]
the_file <- paste(getwd())
the_file
?setwd
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
x <- 1:4
y <- makeVector(x)
cachemean(y)
?matrix
xxx <- matrix()
xxx
inv <- NULL
class(xxx)
class(inv)
class(y)
class(cachemean(y))
y
?mean
?solve
x <- matrix(c(1,0,1,2,4,0,3,5,6), nrow=3, ncol=3)
x
x <- matrix(c(1,0,1,2,4,0,3,5,6), nrow=3, ncol=3)
x <- matrix(c(1,0,1,2,4,0,3,5,6), nrow=3, ncol=3)
x
y <- makeCacheMatrix(x)
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL
set <- function(y) {
x <<- y
inv <<- NULL
}
get <- function() x
setinv <- function(solution) inv <<- solution
getinv <- function() inv
list(set = set, get = get,
setinv = setinv,
getinv = getinv)
}
cacheSolve <- function(x, ...) {
inv <- x$getinv()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
mtx <- x$get()
inv <- solve(mtx, ...)
x$setinv(inv)
inv
}
y <- makeCacheMatrix(x)
cacheSolve(y)
y
class(cacheSolve(y))
cacheSolve(y)
y[1]
y[[1]
y[[1]]
y[[1]]
names(y)
library(datasets)
data(iris)
?iris
head(iris)
aggregate(iris$Sepal.Length, by=list(iris$Species), FUN=mean)
aggregate(iris$Sepal.Length, by=list(iris$Species), FUN=mean)[1]
aggregate(iris$Sepal.Length, by=list(iris$Species), FUN=mean)[2]
aggregate(iris$Sepal.Length, by=list(iris$Species), FUN=mean)
rowMeans(iris[,1:4])
apply(iris, 1, mean)
# apply(iris[, 1:4], 1, mean)
apply(iris[, 1:4], 1, mean)
apply(iris[, 1:4], 2, mean)
library(datasets)
data(mtcars)
?mtcars
head(mtcars)
mean(mtcars$mpg, mtcars$cyl)
tapply(mtcars$mpg, mtcars$cyl, mean)
split(mtcars, mtcars$cyl)
lapply(mtcars, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
means_by_cyl <- tapply(mtcars$mpg, mtcars$cyl, mean)
means_by_cyl$4 - means_by_cyl$8
means_by_cyl$"4" - means_by_cyl$"8"
colnames(mean_by_cyl)
colnames(means_by_cyl)
means_by_cyl
names(means_by_cyl)
class(means_by_cyl
means_by_cyl["4"]
class(means_by_cyl)
means_by_cyl["4"]
means_by_cyl["4"] - means_by_cyl["8"]
debug(ls)
?ls
ls
exit
quit
means_by_cyl <- tapply(mtcars$mpg, mtcars$cyl, mean)
means_by_cyl["4"] - means_by_cyl["8"]
undebug(ls)
undebug(ls)
means_by_cyl <- tapply(mtcars$mpg, mtcars$cyl, mean)
means_by_cyl["4"] - means_by_cyl["8"]
means_by_cyl
head(mtcars)
hp_means_by_cyl <- tapply(mtcars$hp, mtcars$cyl, mean)
hp_means_by_cyl
hp_means_by_cyl["4"] - means_by_cyl["8"]
hp_means_by_cyl <- tapply(mtcars$hp, mtcars$cyl, mean)
hp_means_by_cyl
hp_means_by_cyl["4"] - hp_means_by_cyl["8"]
library(datasets)
data(iris)
?iris
head(iris)
aggregate(iris$Sepal.Length, by=list(iris$Species), FUN=mean)
hp_means_by_cyl <- tapply(mtcars$hp, mtcars$cyl, mean)
hp_means_by_cyl
hp_means_by_cyl["4"] - hp_means_by_cyl["8"]
DT1 <- data.table(x=c(`a', `a', `b', `dt1'), y=1:4)
DT2 <- data.table(x=c('`a', `b', `dt2'), z=5:7)
DT1
DT2
library(data.table)
install.packages("data.table")
library(data.table)
DT1 <- data.table(x=c(`a', `a', `b', `dt1'), y=1:4)
DT2 <- data.table(x=c('`a', `b', `dt2'), z=5:7)
DT1
DT2
DT1 <- data.table(x=c('a', 'a', 'b', 'dt1'), y=1:4)
DT2 <- data.table(x=c('a', 'b', 'dt2'), z=5:7)
DT1
DT2
the_file <- "/Users/JerryTsai/userjst/individ/knowledg/cur/jhu.sph/ds03_getdata/quizzes/quiz01/getdata-data-ss06hid.csv"
q01 <- read.csv(file=the_file,head=TRUE,sep=",")
colnames(q01)
table(quiz01$VAL)
table(q01$VAL)
table(q01$VAL)
library(xlsx)
the_file <- "/Users/JerryTsai/userjst/individ/knowledg/cur/jhu.sph/ds03_getdata/quizzes/quiz01/getdata-data-DATA.gov_NGAP.xlsx"
colIndex <- 7:15
rowIndex <- 18:23
q03 <- read.xlsx(file=the_file, sheetIndex = 1, header=TRUE, colIndex=colIndex, rowIndex=rowIndex)
head(q03)
install.packages("xlsx")
library(xlsx)
the_file <- "/Users/JerryTsai/userjst/individ/knowledg/cur/jhu.sph/ds03_getdata/quizzes/quiz01/getdata-data-DATA.gov_NGAP.xlsx"
colIndex <- 7:15
rowIndex <- 18:23
q03 <- read.xlsx(file=the_file, sheetIndex = 1, header=TRUE, colIndex=colIndex, rowIndex=rowIndex)
head(q03)
colnames(q03)
sum(q03$Zip*q03$Ext,na.rm=T)
library(XML)
the_file <- "/Users/JerryTsai/userjst/individ/knowledg/cur/jhu.sph/ds03_getdata/quizzes/quiz01/getdata-data-restaurants.xml"
quiz03 <-xmlTreeParse(the_file, useInternal=TRUE)
rootNode <-xmlRoot(quiz03)
xmlName(rootNode)
rootNode[[1]]
sum(xpathSApply(rootNode,"//zipcode",xmlValue) == "21231")
the_file <- "/Users/JerryTsai/userjst/individ/knowledg/cur/jhu.sph/ds03_getdata/quizzes/quiz01/getdata-data-ss06pid.csv"
q05 <- read.csv(file=the_file,head=TRUE,sep=",")
install.packages("data.table")
?fread
library(data.table)
?fread
q05 <- fread(file=the_file,head=TRUE,sep=",")
q05 <- fread(the_file)
DT <- q05
DT[, mean(pwgtp15), by=SEX]
set.seed(13435)
X <-data.frame("var1" = sample (1:5), "var2" = sample(6:10), "var3" = sample(11:15)
X <- X[sample(1:5), ]; X$var2[c(1, 3)] = NA
X <-data.frame("var1" = sample (1:5), "var2" = sample(6:10), "var3" = sample(11:15))
X <- X[sample(1:5), ]; X$var2[c(1, 3)] = NA
X
X[, 1]
X[, "var1"]
X[1:2, "var2"]
X[(X$var1 = 3 & X$var3 > 11), ]
X[(X$var1 <= 3 | X$var3 > 15), ]
X[(X$var1 <= 3 & X$var3 > 11), ]
X
X[(X$var1 <= 3 & X$var3 > 11), ]
X[(X$var1 <= 3 | X$var3 > 15), ]
X
X <- X[sample(1:5), ]; X$var2[c(1, 3)] = NA
X
set.seed(13435)
X <-data.frame("var1" =sample (1:5), "var2" = sample(6:10), "var3" = sample(11:15))
X <- X[sample(1:5), ]; X$var2[c(1, 3)] = NA
X
X[(X$var1 <= 3 & X$var3 > 11), ]
X[(X$var1 <= 3 & X$var3 > 11), ]
X[(X$var1 <= 3 | X$var3 > 15), ]
X[which(X$var2 > 8), ]
sort(X$var1)
sort(X$var1, decreasing=TRUE)
sort(X$var2, na.last=TRUE)
X[order(X$var1), ]
X[order(X$var1, X$var3), ]
library(plyr)
arrange(X, var1)
arrange(X, var1)
arrange(X, desc(var1))
X$var4 <- rnorm(5)
X
Y <- cbind(X, rnorm(5))
Y
#
# name: plot1.R
# author: Jerry Tsai
# last updated: 2014-09-07
# For DS04: Exploratory Data Analysis, Project 1
#
#
# Read in data
#
## Could make the subsetting of the power consumption data set by
## using readLines(), making reading the entire text file unnecessary,
## or subsetting on Date, which is a text string, using:
##   consumption$Date %in% c('01/02/2007', '02/02/2007')
## Instead, will convert all Dates into R date values before subsetting
##
## Read-in validated per prior examination
consumption <- read.table("../data/household_power_consumption.txt", sep=";", header=TRUE, na.strings=c("?"))
consumption$RDate <- as.Date(strptime(consumption$Date, "%d/%m/%Y"))
## Create R datetime variable in the analysis data set
anlyDS <- consumption[which(consumption$RDate %in% as.Date(c('2007-02-01', '2007-02-02'))), ]
anlyDS$RDateTime <- strptime(paste(anlyDS$Date, anlyDS$Time), format = "%d/%m/%Y %H:%M:%S")
#
# Generate Plot 1
# Histogram of global active power
#
png(file="plot1.png") # Default width and height are each 480 pixels
hist(anlyDS$Global_active_power, col="red", main="Global Active Power", xlab="Global Active Power (kilowatts)")
dev.off()
getwd()
library(ggplot2)
str(mpg)
qplot(displ, hwy, data=mpg)
qplot(displ, hwy, data=mpg, color=drv)
qplot(displ, hwy, data=mpg, geom=c("point", "smooth"))
qplot(hwy, data=mpg, fill=drv)
qplot(displ, hwy, data=mpg, facets=.~drv)
qplot(displ, hwy, data=mpg, facets=.~drv)
qplot(hwy, data=mpg, facets=drv~., binwidth=2)
testdat <- data.frame(x=1:100, y=rnorm(100))
testdat[50, 2] <- 100  ## Outlier!
plot(testdat$x, testdat$y, type="l", ylim=c(-3,3))
g <- ggplot(testdat, aes(x=x, y=y))
g + geom_line()
g + geom_line() + ylim(-3, 3)
g + geom_line() + coord_cartesian(ylim=c(-3, 3))
cutpoints <- quantile(x, seq(0, 1, length=4), na.rm=TRUE)
x <- rnorm(100)
cutpoints <- quantile(x, seq(0, 1, length=4), na.rm=TRUE)
cutpoints
library(datasets)
q <- xyplot(Ozone ~ Wind, data=airquality)
class(q)
library(datasets)
library(lattice)
qq <- xyplot(Ozone ~ Wind, data=airquality)
class(q)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
q01 <- xyplot(weight ~ Time | Diet, BodyWeight)
class(q01)
x <-rnorm(100)
y <-rnorm(100)
q01 <- xyplot(x ~ y)
class(q01)
library(nlme)
library(lattice)
q01 <- xyplot(weight ~ Time | Diet, BodyWeight)
class(q01)
?llines
?text
?axis
?points
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data=airquality)
print(p)
?print.trellis
?par
?trellis.par.set
?splom
qplot(Wind, Ozone, data=airquality, facets=.~factor(Month))
library(datasets)
data(airquality)
qplot(Wind, Ozone, data=airquality, facets=.~factor(Month))
library(ggplot2)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data=airquality, facets=.~factor(Month))
qplot(Wind, Ozone, data=airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data=airquality, facets=.~Month
)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
setwd("/Users/JerryTsai/userjst/individ/knowledg/cur/jhu.sph/ds05_reproducible/projects/project01/RepData_PeerAssessment1")
library(plyr)
activityDF <- read.csv("activity.csv", header=TRUE)
# str(activityDF)
activityDF$Rdate <- as.Date(strptime(activityDF$date, "%Y-%m-%d"))
##
## 1) Make a histogram of the total number of steps taken each day
##
by_date <- ddply(activityDF, .(Rdate), summarize, steps=sum(steps, na.rm=TRUE))
# Alternative way of summing the steps by date,
# using a data.table, to check work, in case you
# are interested
#
# library(data.table)
# activityDT <- as.data.table(activityDF)
# by_date <- tester[, sum(steps, na.rm=TRUE), by=date]
# setnames(by_date, c("date", "steps") )
library(ggplot2)
qplot(steps, data=by_date, geom="histogram", binwidth=2500, xlab="Total # of Steps per Day", main="Steps each day")
```
```{r mean_total_steps}
##
## 2) Calculate and report the mean and median
##    total number of steps taken per day
##
## Because of the earlier removal of NAs, setting
## na.rm=TRUE will do nothing, but I'm leaving it in
median_steps_per_day <- median(by_date$steps, na.rm=TRUE)
mean_steps_per_day <- as.integer(round(mean(by_date$steps, na.rm=TRUE)))
##
## 1) Make a time series plot (i.e. type = "l") of the
##    5-minute interval (x-axis) and the average number of
##    steps taken, averaged across all days (y-axis)
##
by_interval <- ddply(activityDF, .(interval), summarize, mean_steps=mean(steps, na.rm=TRUE))
ggplot(by_interval, aes(interval, mean_steps)) + geom_point(size=2) + geom_line() + xlab("Time (in 5-minute intervals)") + ylab("Steps") + ggtitle("Average # of Steps Taken Across a Day")
number_of_NA <- sum(is.na(activityDF$steps))
activityNA <- activityDF[which(is.na(activityDF$steps)), !(names(activityDF) %in% c("steps"))]
graft_info <- merge(by_interval, activityNA, by=c("interval"))
## Rename "mean_steps"" variable as "steps""
names(graft_info)[names(graft_info)=="mean_steps"] <- "steps"
##
## 3) Create a new dataset that is equal to the original
##    dataset but with the missing data filled in.
##
## Combine rows with imputed data with rows with actual data in one data frame
imputedDF <- join(graft_info, activityDF[which(!is.na(activityDF$steps)), ], type="full")
sortedDF <- imputedDF[order(imputedDF$Rdate, imputedDF$interval), ]
imputed_by_date <- ddply(imputedDF, .(Rdate), summarize, steps=sum(steps, na.rm=TRUE))
qplot(steps, data=imputed_by_date, geom="histogram", binwidth=2500, xlab="Total # of Steps per Day", main="Steps each day")
imputed_median_steps_per_day <- median(imputed_by_date$steps, na.rm=TRUE)
imputed_mean_steps_per_day <- as.integer(round(mean(imputed_by_date$steps, na.rm=TRUE)))
combo_set <- rbind(cbind(by_date, source="actual"),
cbind(imputed_by_date, source="imputed"))
ggplot(combo_set, aes(steps, fill=source)) +
geom_histogram(binwidth=2500, alpha=.5, position="identity") +
ggtitle("Actual vs. Imputed, Overlaid")
?transform
transform(sortedDF, dayFlag = as.factor(ifelse(weekday(sortedDF$Rdate) %in% c("Saturday","Sunday"), "Weekend", "Weekday")) )
transform(sortedDF, dayFlag = as.factor(ifelse(weekdays(sortedDF$Rdate) %in% c("Saturday","Sunday"), "Weekend", "Weekday")) )
head(sortedDF)
weekdayDF <- transform(sortedDF, dayFlag = as.factor(ifelse(weekdays(sortedDF$Rdate) %in% c("Saturday","Sunday"), "Weekend", "Weekday")) )
head(weekdayDF)
table(weekdayDF$Rdate, weekdayDF$dayFlag)
?ddply
by_dayFlag_interval <- ddply(weekdayDF, .(dayFlag, interval), summarize, mean_steps=mean(steps, na.rm=TRUE))
head(by_dayFlag_interval)
ggplot(by_dayFlag_interval, aes(steps) +
geom_histogram(binwidth=2500, alpha=.5, position="identity") +
geom_line()
)
ggplot(by_dayFlag_interval, aes(steps)) +
geom_line() +
xlab("Interval") +
ylab("Number of steps")
head(by_dayFlag_interval)
ggplot(by_dayFlag_interval, aes(mean_steps)) +
geom_line() +
xlab("Interval") +
ylab("Number of steps")
ggplot(by_dayFlag_interval, aes(mean_steps, interval)) +
geom_line() +
xlab("Interval") +
ylab("Number of steps")
ggplot(by_dayFlag_interval, aes(mean_steps, interval)) +
geom_line() +
facet_wrap( ~dayFlag, nrow=2)
xlab("Interval") +
ylab("Number of steps")
ggplot(by_dayFlag_interval, aes(interval, mean_steps)) +
geom_line() +
facet_wrap( ~dayFlag, nrow=2)
xlab("Interval") +
ylab("Number of steps")
by_dayFlag_interval
ggplot(by_dayFlag_interval, aes(interval, mean_steps)) +
geom_line() +
facet_wrap( ~dayFlag, nrow=2) +
xlab("Interval") +
ylab("Number of steps")
